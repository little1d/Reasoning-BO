#!/usr/bin/env python
# -*- coding: utf-8 -*-
r"""
@DATE: 2025-03-04 11:21:44
@File: src/utils/metric.py
@IDE: vscode
@Description:
    ä» ax åˆ°ç»“æœå­˜å‚¨çš„è½¬æ¢å‡½æ•°ï¼Œè¿˜åŒ…æ‹¬ä¸€äº› io å‡½æ•°
"""
import numpy as np
from ax import Experiment, Trial
import csv
import os


def save_trial_data(
    experiment: Experiment,
    trial: Trial,
    save_dir: str,
    filename: str,
) -> None:
    """è¿›è¡Œä¸€è½® Trial/BatchTrial åï¼Œä¿å­˜ arms å’Œ metricsåˆ°æœ¬åœ°ï¼Œä½œä¸ºå‚è€ƒåœ¨ä¸‹ä¸€è½®æä¾›ç»™ llm

    Parameters
    ----------
    experiment : Experiment
        å½“å‰å®éªŒå®ä¾‹
    trial : Trial/BatchTrial
        å½“å‰ trial å®ä¾‹ï¼Œå¯ä¸º Trial å’Œ BatchTrial
    save_dir : str
        json å’Œ csv æ–‡ä»¶ä¿å­˜ç›®å½•
    filename : str
        json å’Œ csv æ–‡ä»¶å
    """
    # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(save_dir, exist_ok=True)

    data_df = experiment.fetch_trials_data(trial_indices=[trial.index]).df

    # æ„å»ºæ•°æ®è®°å½•
    # armséœ€è¦ä» trial object æ‹¿ï¼Œmetric è¦ä» experiment å¯¹è±¡æ‹¿ã€‚å…ˆå…¨éƒ¨è®°å½•æˆ recordï¼Œå†å­˜å‚¨
    # æ²¡åŠæ³•ï¼Œæˆ‘ä¹Ÿä¸æƒ³å†™ğŸ’©å±±çš„
    record = {
        "trial_index": trial.index,
        "arms_parameters": [
            {
                "arm_name": arm.name,
                **{
                    key: round(value, 3)
                    for key, value in arm.parameters.items()
                },
            }
            for arm in trial.arms
        ],
        "metric_data": [
            {
                "arm_name": row["arm_name"],
                "metric_name": row["metric_name"],
                "mean": row["mean"],  # ä¿ç•™åŸå§‹ç²¾åº¦
            }
            for _, row in data_df.iterrows()
        ],
    }
    # json_file = os.path.join(save_dir, f"{filename}.json")

    # ä¿å­˜JSONï¼Œä½†å…¶å®æ²¡å•¥å¿…è¦ï¼Œå¯ä»¥è°ƒè¯•ï¼Œçœ‹çœ‹è¿™ä¸€è½®å®éªŒ
    # with open(json_file, 'a+') as f:
    #     json.dump(record, f, indent=2)
    #     f.write('\n')

    # ç”Ÿæˆç»“æ„åŒ–CSVè¡¨æ ¼
    # è·å–å‚æ•°åˆ—åï¼ˆæ’é™¤arm_nameï¼‰
    param_columns = [
        k for k in record["arms_parameters"][0] if k != "arm_name"
    ]

    # æŒ‰metricåˆ†ç»„ç”Ÿæˆè¡¨æ ¼
    metrics = {m["metric_name"] for m in record["metric_data"]}

    for metric in metrics:
        csv_filename = os.path.join(save_dir, f"{filename}_{metric}.csv")
        rows = []

        # æ„å»ºè¡¨æ ¼è¡Œæ•°æ®
        for arm in record["arms_parameters"]:
            # è·å–è¯¥armåœ¨å½“å‰ metric çš„meanå€¼
            mean_value = next(
                (
                    m["mean"]
                    for m in record["metric_data"]
                    if m["arm_name"] == arm["arm_name"]
                    and m["metric_name"] == metric
                ),
                None,
            )

            if mean_value is not None:
                row = {
                    "trial_index": arm["arm_name"],
                    **{col: arm[col] for col in param_columns},
                    f"{metric}_mean_value": round(mean_value, 3),
                }
                rows.append(row)

        # æŒ‰arm_nameæ’åº
        rows.sort(key=lambda x: [int(n) for n in x["trial_index"].split('_')])

        # å†™å…¥CSVæ–‡ä»¶ï¼Œå¢é‡å­˜å‚¨
        with open(csv_filename, 'a+', newline='') as f:
            writer = csv.DictWriter(
                f, fieldnames=["arm_name"] + param_columns + ["mean"]
            )
            if f.tell() == 0:
                writer.writeheader()
            writer.writerows(rows)


def extract_metric(exp: Experiment, metric_name: str) -> np.ndarray:
    """
    æå–å®éªŒå¯¹è±¡ä¸­æŒ‡å®šmetricçš„å‡å€¼åºåˆ—ï¼Œç”¨äºæ‰€æœ‰å®éªŒç»“æŸåï¼Œç»“æœçš„å±•ç¤ºã€‚å…¶å®åœ¨ save_trial_data å‡½æ•°ä¸­ï¼Œä¼šæŠŠ
    æ‰€æœ‰çš„ metrics å¢é‡å­˜å‚¨åˆ° xxx_metric.csc ä¸­ï¼Œä½†é‚£æ˜¯ä»¥ arm ä¸ºæœ€å°å•ä½çš„ã€‚å¯¹äº BatchTrial æ¥è¯´ï¼Œä¸€ä¸ª Batch
    é‡Œä¸åŒ arm çš„ metric å€¼å¯èƒ½ç›¸å·®å¾ˆå¤§ã€‚é’ˆå¯¹æœ€åç»“æœç»˜å›¾è€Œè¨€ï¼Œå–å‡å€¼æ˜¯å¾ˆåˆç†çš„ï¼Œå¯ä»¥åæ˜ ä¸Šä¸€è½® sample çš„ candidates æ•´ä½“æ°´å¹³ï¼Œ
    éšç€å®éªŒçš„è¿›è¡Œï¼Œmean ç†è®ºä¸Šæ˜¯é€æ¸å‡é«˜çš„ã€‚
    å‚æ•°ï¼š
        exp: å®éªŒå¯¹è±¡
        metric_name: éœ€è¦æå–çš„æŒ‡æ ‡åç§°ï¼ˆå¦‚'hartman6'ï¼‰ï¼Œåœ¨ objective/constriant ä¸­å®šä¹‰çš„"name"ä¸€æ ·
    è¿”å›ï¼š
        np.ndarray: æŒ‰ trial_index é¡ºåºæ’åˆ—çš„æŒ‡æ ‡å‡å€¼æ•°ç»„
        å¯¹äºBatchTrialè‡ªåŠ¨å–è¯¥æ‰¹æ¬¡çš„å‡å€¼
    """
    # è·å–åŸå§‹æ•°æ®å¹¶è¿‡æ»¤ç›®æ ‡æŒ‡æ ‡
    df = exp.fetch_data().df
    metric_df = df[df['metric_name'] == metric_name]

    # æŒ‰trialåˆ†ç»„å¤„ç†å‡å€¼
    results = []
    for trial_idx, group in metric_df.groupby('trial_index'):
        # åˆ¤æ–­æ˜¯å¦ä¸ºBatchTrialï¼ˆä¾æ®æ¯ç»„armæ•°é‡ï¼‰
        if len(group) > 1:
            batch_mean = group['mean'].mean()
            results.append((trial_idx, batch_mean))
        else:
            results.append((trial_idx, group['mean'].iloc[0]))

    # æŒ‰trialé¡ºåºæ’åˆ—å¹¶è½¬æ¢ä¸ºæ•°ç»„
    sorted_results = sorted(results, key=lambda x: x[0])
    return np.array([val for _, val in sorted_results])
